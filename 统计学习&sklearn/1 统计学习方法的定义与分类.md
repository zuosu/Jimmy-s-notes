# 周报（时间：220909）
本周主要完成的工作有：  
1. 学习了李航《统计学习方法》第一章，整理学习笔记如下；
2. 学习了Pandas的基本数据结构、数据读取与操作、数据清洗、数据的基本统计分析。
# 1 统计学习及监督学习概论
## 1.1 统计学习方法的定义与分类
### 1.1.1 定义
统计学习（statistical Machine Learning）是关于计算机基于数据构建概率模型并运用模型对数据进行预测与分析的一门学科。拆分来看，统计学习
* 以计算机和网络为平台
* 以数据为研究对象
* 以预测和分析数据为目的
* 以方法为中心
* 是多领域交叉的学科

简而言之，统计学习实现了一个从已知到未知的过程，利用已知数据和各种学科理论来对未知的新数据进行一个预测和分析。

### 1.1.2 统计学习的步骤
1. 得到一个有限的训练集数据集合
2. 确定学习模型的集合（模型，此集合称为假设空间）
3. 确定模型选择的准则（策略）
4. 实现求解最优模型的算法（算法）
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测和分析

![](https://files.mdnice.com/user/25190/54882d71-1e28-4745-9bb6-badb6276e9fb.png)

为了更直观的表述统计学习方法的步骤，观察上面的流程图。首先给定一个训练集，这里面假设包含N个样本，然后放入到学习系统里面，学习系统就包含了模型、策略和算法，然后通过学习系统对于训练集中信息的不断学习，得到了一个最优模型，也就是对应了之前第五步。最后，输入一个新的实例，代入到最优模型中，通过预测系统得到了一个新的输出，也就是对于新数据进行的预测和分析。这就是统计学习方法的一个大概步骤。

## 1.2 统计学习方法的分类

![](https://files.mdnice.com/user/25190/fd269539-c2fd-4dae-acc1-5f3cc22f6ccd.png)

监督学习中的几个概念
-  输入空间（Input Space）：输入的所有可能取值的集合；
-   实例（Instance）：每一个具体的输入，通常由特征向量（Feature Vector）表示；
-   特征空间（Feature Space）：所有特征向量存在的空间大多时候，输入空间和特征空间是相同的。

-   输出空间（Output Space）：输出的所有可能取值的集合   根据变量的不同类型，要解决的问题可以分为回归问题、分类问题和标注问题。
	-   输入变量与输出变量均为连续变量的预测问题——回归问题
	-   输出变量为有限个离散变量的预测问题——分类问题
	-   输入变量与输出变量均为变量序列的预测问题—— 标注问题

符号表示

![](https://files.mdnice.com/user/25190/23fca74f-0b8b-441c-af48-4954339e1485.png)

在监督学习中，训练集中的每一个样本，都是以输入-输出对出现的。对于监督学习，主要就是研究输入到输出之间的统计规律，所以要有关于输入和输出的基本假设。

![](https://files.mdnice.com/user/25190/f50f2501-dcd1-49ab-94c7-1913d91fd963.png)

映射关系以模型来表示的话，主要有两种，一种是条件概率分布的形式，一种是决策函数的形式。条件概率分布的形式其实就是概率模型，而决策函数的形式就是非概率模型。

![](https://files.mdnice.com/user/25190/0d328d9b-e43e-4fdb-8078-cb232053a36f.png)

流程图

![](https://files.mdnice.com/user/25190/701d3f09-718a-46ce-bff3-13e6cfe0c031.png)

首先要有一个训练数据集，然后通过学习系统的学习，训练出一个模型来，这个模型既可以表达成条件概率分布的形式，也可以表达成决策函数的形式。可以看出，和之前的模型表达有些不一样，加了一个小帽子。这个小帽子，就代表着模型是通过学习训练而得到的。

然后，给一个新的实例，即只给输入信息，通过预测系统就可以得到一个输出，这个输出也可以表达成决策函数或者条件概率分布预测值的形式。之所以通过Max，选择使条件概率分布最大的y值，就是因为我们预测的思想就是想找到出现的可能性最大的值。

无监督学习的几个概念：

![](https://files.mdnice.com/user/25190/4083cfbd-8d6e-4bab-a515-e96acce0e83c.png)
因为无监督学习，本质是研究数据中的潜在结构内容，也就是需要学习隐含在数据结构内部的信息，所以无监督学习对应的不是输出空间，而是隐式结构空间。

流程图

![](https://files.mdnice.com/user/25190/90ac281c-8d23-4fde-98a1-518dbad4d7a2.png)


强化学习

![](https://files.mdnice.com/user/25190/a2d4a61a-f237-4d17-9938-4e33686b716a.png)
假如在环境中观察到一个状态和一个奖励，如果采取某一动作，环境就可以根据智能系统来决定下一个状态和下一个奖励，之后不停地循环。
当然，智能系统决定下一个状态和下一个奖励是根据长期累积奖励最大化来实现的。
强化学习可以基于策略，也可以基于价值，**基于策略的则是选择最优策略**，**基于价值是选择最优价值**，都可以得到一个最优模型。

## 1.3 统计学习方法的三要素

构成统计学习方法的三要素——模型、策略、算法。对于监督学习、无监督学习、强化学习，这三要素都是必备的，只不过形式不同。对于监督学习，处理的是有标注的数据，数据中输出空间的类型已知，所以相应的模型、策略以及算法都是比较具体的。但对于无监督学习，处理的数据是无标注信息的，我们希望找到隐含在数据内部的结构信息，这时候的三要素——模型、策略、算法就不那么具体了。
### 1.3.1 监督学习的三要素
![](https://files.mdnice.com/user/25190/a12b78b7-a038-45d7-b974-cb6bb24f9e5a.png)

### 1.3.2 无监督学习的三要素

![](https://files.mdnice.com/user/25190/e2f82b6c-7fc1-4a00-8af5-4c5e02f4f183.png)

模型中涉及到的z来自于隐式结构空间，此时模型有三种表达方式，一种是函数形式，另外两种是条件概率分布的形式。

对于无监督学习，策略同样是优化目标函数。当然，因为无监督学习处理的数据是无标注信息的，更具有多变性，相应的目标函数会根据数据的不同而发生变化。

## 1.4 模型评估与模型选择
### 1.4.1 模型评估
关于模型拟合的好坏，我们可以通过训练集计算训练误差来度量。以训练集代表已知数据，训练误差就反映了模型对已知数据的拟合能力。

关于模型的预测效果，可以通过测试集来度量。我们以测试集代表未知数据。假如存在一个样本容量为N'的测试集，我们将测试集中所有的实例都放到预测系统里面，根据之前训练出的模型，就可以计算出一系列的预测值。这些预测值与真实值之间的差异，就是测试误差，通常以测试误差来度量模型对未知数据的预测效果。

1. 训练误差
![](https://files.mdnice.com/user/25190/31fcdfe8-5a02-4bd2-86e6-a90868a4d5d0.png)
既然是训练误差，那就是在训练集上得到的误差。可以用决策函数的形式表示出训练得到的模型，其中X、Y分别代表输入和输出变量。训练误差是训练数据集的平均损失，具体来说就是先计算出训练集上每个样本的损失，然后再计算平均值。
2. 测试误差
![](https://files.mdnice.com/user/25190/c317d60d-2403-4eca-a82a-3212ef211916.png)
这里所用的模型是之前通过训练集训练出来的。但要注意，测试误差是根据测试数据集所得。具体来说，就是计算测试集中每个样本点的损失，再求平均值。
3. 误差率与准确率
![](https://files.mdnice.com/user/25190/38cb40b4-415f-4898-b198-30d1666ce115.png)

特别地，当计算测试误差时，选取的损失函数是一个0-1示性函数，那么就可以得到误差率。所以说，误差率与准确率其实是测试误差的两个特例。

误差率实际上体现的是，在测试集中预测错误的样本点的个数占测试集样本总个数的比例。准确率则是预测正确的样本点个数占测试集样本总个数的比例。很明显，误差率和准确率之和为 1。

### 1.4.2 模型选择

在模型选择时，我们当然希望训练误差和测试误差都很小，但是当训练误差很小的时候，测试误差并不小，因此需要二者的一个平衡。

![](https://files.mdnice.com/user/25190/fba1045e-4b69-4650-897f-b96c30b42fc2.png)

图中，横轴代表模型的复杂度，纵轴代表预测误差。随着模型复杂度的增加，训练误差会越来越小，直到接近于0，而测试误差会先减小，达到一个最小值，然后再增大。

选择模型的时候，一定要注意：防止过拟合的现象出现。即遵循奥卡姆剃刀原理，选择的模型既要有良好的拟合效果，复杂度又适当，或者说选择使训练误差和测试误差同时达到比较小的模型。

## 1.5 正则化与交叉验证

### 1.5.1 正则化

为了平衡模型的对已知数据和未知数据的预测能力，我们在原来的经验风险上加上了正则化项，以此度量模型复杂度。经验风险与正则化项一起构成结构风险函数。

![](https://files.mdnice.com/user/25190/33d103a7-7b0c-413b-8d0a-51b45fd6d43c.png)

正则化，就是通过使结构风险最小化来实现的。在正则化的一般形式中，目标函数为结构风险。其中，第一部分是经验风险，用以度量模型在训练集中的平均损失，第二部分被称为正则化项或惩罚项，J(f) 度量模型的复杂度，系数 λ，用以调整经验风险和模型复杂度之间的关系。 λ越大就越重视模型的复杂度，越小则越重视拟合能力，选出来的模型可能会出现过拟合。我们的目的是选择拟合能力和泛化能力都很强的模型。

正则化项有很多种形式，最常见的有以下两种。

![](https://files.mdnice.com/user/25190/bb4493fb-c781-42da-9919-9a10ba65e6f1.png)

第一个正则化项是L1范数，即参数绝对值之和，更适用于***特征筛选***，在回归分析中，就是大家熟知的Lasso回归，可以选择出一个稀疏的模型。稀疏模型，指的非零参数个数很少的模型。

第二个正则化项是L2范数，即参数的平方和，主要用以防止过拟合现象的出现，在回归分析中，是大家熟悉的岭回归。L2正则化项的构成，使得在正则化的时候，参数可以无限的接近于0，但是与L1范数不同，这里参数只是接近于0，很难出现直接等于0的情况。所以，这一类正则化项，可以使得模型越来越简单，防止过拟合现象的出现，但无法起到特征筛选的作用。

> 为什么L2范数这里有一个1/2？
>主要是出于数学运算的方便。求极值时，如果使用求导的方法，那么1/2恰好可以约去。

正则化，就用来选择经验风险和模型复杂度同时都很小的模型。这种思想非常符合奥卡姆剃刀原理。即在模型选择时，选择假设空间中既能很好地解释已知数据，结构又十分简单的模型。

### 1.5.2 交叉验证
在样本的数据量足够充足的情况下，通常可以将数据集随机地分为训练集、验证集，还有测试集三部分。

-   训练集（Training Set）：用以训练模型
-   验证集（Validation Set）：用以选择模型
-   测试集（Test Set）：用以最终对学习方法的评估

通常，我们假设验证集中有足够多的数据，这样，通过训练集所得到的模型放入验证集里，选择预测误差最小的那个模型，就是最优模型了。但是，现实情况中，样本数据通常是不充足的。那么，为了选择一个好的模型，可以采用交叉验证的方法。

交叉验证的基本思想就是，重复使用数据，以解决数据不足的这种问题。通常使用这样三种交叉验证法：简单交叉验证，S折交叉验证，还有留一交叉验证。
1. 简单交叉验证
简单交叉验证法，是将数据集随机的分为两个部分，一个作为训练集，一个作为测试集。举个例子，假如我们将样本的70%作为训练集，30%作为测试集，那么在不同的情况下，可以通过训练集得到不同的学习模型，将学习训练得到的不同模型放到测试集上，计算测试误差，测试误差最小的模型则是最优模型。
2. S折交叉验证
S折交叉验证，随机将数据分为 S 个互不相交、大小相同的子集，其中以 S-1 个子集作为训练集，余下的子集作为测试集。
![](https://files.mdnice.com/user/25190/57508a8f-43a8-44f5-9a90-571203ccfc09.png)
假如S=10，我们可以将数据集均匀的分为T1，T2，......  T10 这十个子集。那么，可以将其中九个子集的并集作为训练集，剩余的那个子集作为测试集。比如，将T1-T9的并集作为训练集，用于训练模型，所得模型记做M1。通过类似的方法，我们还可以得到模型M2，M3，...... M10。分别在每个模型相应的测试集中计算测试误差，并进行比较，测试误差最小的模型，就是最优模型。

3. 留一交叉验证
留一交叉验证，可以认为是S折交叉验证的特殊情况，即 S=N 的情况，这里的 N 指的是数据集的样本容量。留一交叉验证，leave-one-out cross validation，也就是每次用N-1个样本训练模型，余下的那个样本测试模型。这是在数据非常缺乏的情况下才使用的方法。

## 1.6 泛化能力
泛化能力，指的是通过某一学习方法训练所得模型，对未知数据的预测能力。但实际上，在对泛化能力度量的时候，我们依然使用的是既有输入又有输出的数据集，只是这组数据是用来测试我们训练所得模型的，所以被称为**测试数据集**。

通常，测试数据集用以评价训练所得模型的泛化能力。由于测试数据集包含的样本有限，仅仅通过测试数据集去评价泛化能力，有时并不可靠，此时需要从理论出发，对模型的泛化能力进行评价。
### 1.6.1 泛化误差
之前计算测试误差所使用的样本为测试集。泛化误差，则是基于整个样本空间的。所以泛化误差是度量对未知数据预测能力的理论值，测试误差则是经验值。

当通过学习系统得到的两个模型对已知数据的预测能力相近时，可以通过泛化误差来比较两者的泛化能力。哪一个模型的泛化误差小，哪一个模型的泛化能力就更强，也就是对未知数据的预测能力能强。

### 1.6.2 泛化误差上界
泛化误差上界对应的是泛化误差的概率上界。在理论上比较两种学习方法所得模型的优劣时，可通过比较两者的泛化误差上界来进行。  

关于泛化误差上界具有两条性质：
-   样本容量的函数：当样本容量增加时，泛化误差上界趋于 0。
-   假设空间容量的函数：假设空间容量越大，模型就越难学，泛化误差上界就越大。  

第一条性质，可以从泛化误差的概念出发辅助理解。泛化误差定义为一个期望值，那么经验值就是以全样本空间作为测试集，计算所得的测试误差，它表示为一个平均值。在平均值中，样本量位于分母的位置，那么随着样本量的增加，平均值则趋于零。

第二条性质，泛化误差上界是假设空间容量的函数，不同的模型，对应不同的泛化误差上界。假设空间是所有可能的模型的集合，那么假设空间容量越大，所有可能的模型类型就会越多，模型也就愈加难以学习，与之对应的泛化误差上界就会越大。

## 1.7 生成模型与判别模型

通过训练集学习出一个模型，一般有两种形式，条件概率的形式和决策函数的形式。这里，通过学习获得模型的方法，又可以分为生成方法和判别方法，与之相对应的模型则是生成模型和判别模型。

### 1.7.1 生成模型
![](https://files.mdnice.com/user/25190/38b329ed-534c-4e0b-b694-140eb49a076d.png)

之所以称为生成模型，是因为每给定一个输入变量X，就可以根据分布函数生成一个输出变量Y。需要注意的是，生成模型中的输入变量和输出变量，都为随机变量。

**典型的生成模型有朴素贝叶斯法，还有隐马可夫模型。**从贝叶斯定理，很容可以理解为何朴素贝叶斯法是生成模型。隐马尔科夫模型其实就是一个时间序列的概率模型。先由一个隐藏的马尔可夫链，随机生成不可观测的状态随机序列，然后再由各个状态生成一个观测，以此得到观测的随机序列。

### 1.7.2 判别模型
![](https://files.mdnice.com/user/25190/92aadfd1-ffe9-4d14-9b17-24f3d3b10204.png)

判别模型，与生成模型不同，可以通过数据直接学习得到决策函数，不需要考虑X和Y的联合分布。所以说，判别方法是有针对性的，研究的是对于特定的输入，应该预测得到一个什么样的输出。

对于判别模型，并不要求输入变量和输出变量均为随机变量。

**典型的判别模型有 k 近邻法、感知机，还有决策树。**

### 1.7.3 生成模型和判别模型之间的区别
从样本量上来比较：
1.  生成模型所需要的数据量较大，因为只有在大数据量的情况下，才能够更好地估计联合概率分布，也就是所有变量的一个全概率模型；
2.  判别模型，是针对性地学习，只需要得到条件概率分布或者决策函数即可，所以不需要像生成模型的那样，必须配备足够多的样本，因此判别模型所需的样本量要少于生成模型。

从目的来比较：

1.  生成模型可以还原联合概率分布，借此可以计算出边际分布和条件概率分布，所以可以提供更多的信息； 
2.  判别模型的目的就是预测，所以准确率往往比生成模型会更高一些。

从过程来比较：

1.  对生成模型而言，样本容量越多，学习到的模型就能够更快地收敛到真实模型上，所以生成模型的收敛速度，较之判别模型更快；
    
2.  判别模型，是直接学习的过程，所以不需要面面俱到，因此可以简化学习问题。
    

从反映数据特征来比较：

1.  生成模型学习到的模型更接近于真实模型，所以能够反映同类数据本身的相似度；
2.  判别模型，并不考虑数据的各项特征，所以并不能像生成模型那样反映数据本身的特性。

最后一条是关于隐变量的，生成模型，可以很好地应对具有隐变量的情况，比如混合高斯模型。
## 1.8 监督学习的应用
根据输入和输出数据的不同类型，可以对监督学习进行一个简单分类。

-   分类问题：输出变量为有限个离散变量  
-   标注问题：输入和输出变量均为变量序列
-   回归问题：输入和输出变量为连续变量

### 1.8.1 分类问题

![](https://files.mdnice.com/user/25190/82c2301a-be68-4940-b455-61b1634b85c0.png)

这里是分类问题的一个流程图。学习到的分类模型或者分类决策函数，称为分类器，相应的预测系统称为分类系统，预测所得到的输出称为类别。有多个类别的时候，是多分类问题。

如何评价分类器的性能？
___
如果给定测试数据集，测试集中样本为$N'$，那么可以利用0-1损失函数得到分类准确率（如下式），这是一个一般的分类器评价指标。
$$
r_{test} = \frac{1}{N'}\sum_{i'=1}^{N'}I(y_{i'}=\hat{f}(x_{i'}))
$$
准确率代表在测试集中正确分类的样本占比。
特别的，对于二分类问题，有自己独特的评价指标，即精确率和召回率。

![](https://files.mdnice.com/user/25190/87265b48-6f55-4ab1-8c7d-92ae1cf8f138.png)

表格中的这几个符号，可以借助英文单词来记忆。预测正确与否分别用 True（做出正确预测，标蓝）和 False（做出错误预测，标红）来表示，预测出来的类别分别用 Positive（正类）和 Negative（负类）表示。

-   TP（True Positive）：把正类样本预测为正类的个数
-   FP（False Positive）：把负类样本预测为正类的个数
-   FN（False Negative）：把正类样本预测为负类的个数
-   TN（True Negative）：把负类样本预测为负类的个数

精确率：
$$
P = \frac{TP}{TP+FP}
$$
表示预测为正类的样本中有多少样本真正属于正类，这是针对**预测结果**的一个指标。分母是预测为正类的样本个数。
召回率:
$$
R = \frac{TP}{TP+FN}
$$
表示正类样本有多少被正确预测了，这是针对**样本本身**的一个指标。分母是样本中本身含有的正类样本的个数。

对于二分类问题，希望精确率和召回率越高越好，于是就有了一个综合指标，**调和值$F_1$**
$$
\frac{2}{F_1} = \frac{1}{P}+\frac{1}{R}
$$

当精确率和召回率都很高的时候，调和值就会很高
___

常见的分类方法和分类的应用领域

![](https://files.mdnice.com/user/25190/38b9b2e0-d0b3-4ac6-b549-7a41c8d3c220.png)

### 1.8.2 标注问题

标注问题，可以认为是分类问题的一个推广，标注问题要求输入和输出变量均为变量序列，而且序列的长度相同，即输入一个维度为 n 的观察的序列，那么相应的要输出一个维度为 n 的标记序列。在保证输入与输出维度一致的情况下允许不同样本有不同的长度。

![](https://files.mdnice.com/user/25190/7e1da62a-c155-4d43-9254-2d52f79ae4c4.png)

标注问题的流程图：

![](https://files.mdnice.com/user/25190/81dd5573-8ec9-4973-b9d4-ee64c02097e9.png)

标注问题的评价指标与分类问题一样，即准确率，精确率和召回率。
几种常见的标注方法和应用领域。

![](https://files.mdnice.com/user/25190/c9eb27ba-96f1-4c2b-84ee-c2d2f0cada59.png)

标注问题举例：
从文章中抽取基本名词短语。比如 Microsoft research，然后对其进行标注

![](https://files.mdnice.com/user/25190/5b89cb38-196b-4ce8-b51b-90fec48e90de.png)

这个句子包含了22个单词，那么输入观测序列长度就为22。现在对每个单词进行标记。这个单词为一个基本短语。

-   如果代表开始，标为B（Begin）；
-   如果代表结束，标为 E（End）；
-   如果既不是表示开始也不是表示结束，标为O（Others）。

标为蓝色的那些，就是输出的部分，也是长度为22的序列，和输入的序列长度一致。

### 1.8.3 回归问题
回归问题，是监督学习中非常重要的一部分，反映输入和输出变量之间的映射关系。所以，相应的学习过程就等价于进行一个**函数拟合**。具体的流程和之前类似。

![](https://files.mdnice.com/user/25190/a8235d68-2fcc-47d5-8ce8-1c46f0ed25ea.png)

-   按照输入的变量的个数分类：一元回归（只有一个变量）、多元回归（有多个变量）
-   按照输入和输出变量之间的关系分类：线性回归、非线性回归

回归模型中，损失函数一般采用平方损失，而求解损失函数最常用的则是最小二乘法（OLS）。

回归问题可以应用在商务领域。举一个例子，比如在股票预测问题中，我们可以通过某公司历史数据中进行股价的预测，股票价格作为因变量，而该公司其他的数据。比如营业额，基本资产，董事会决策等作为自变量，构建回归模型，进行模型学习，然后通过训练所得模型预测一个未来股票价格。