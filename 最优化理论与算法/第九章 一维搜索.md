# 周报（时间：2207022）
本周主要完成的工作有：  
1. Qt看到了53p，学习了绘图事件，文件操作，练习了翻金币案例。
2. 《李宏毅2021/2022春机器学习课程》看到了12p，学习了机器学习和深度学习的基本概念。
3. 《最优化理论与算法》看到了35p，学习了Rosen投影梯度法，Frank-Wolfe方法，外点罚函数法，内点罚函数法。
4. 整理了《最优化理论与算法》第八章 算法和第九章 一维搜索中的黄金分割法内容，如下。

# 第九章 一维搜索

![](https://files.mdnice.com/user/25190/ac197b84-24da-43e8-b4be-67fa42473ca9.png)



## 9.1 一维搜索的概念
在许多迭代下降算法中，具有一个共同特点，这就是得到点$x_k$后，需要按照某种规则确定方向$d_k$，再从$x_k$出发沿方向$d_k$在直线（或射线）上求目标函数的极小点，从而得到$x_k$的后继点$x_k^{'}$。重复以上做法，直至求得问题的解。这里所谓求目标函数在直线上的极小点，称为一维搜索，或称为线搜索。

![](https://files.mdnice.com/user/25190/03fe696f-2224-445b-a671-7f0ac504a537.png)

## 9.2 试探法
### 9.2.1 0.618法
0.618法（黄金分割法）适用于单峰函数。

#### 单峰函数
* 定义

设f是定义在闭区间$[a,b]$上的一元函数，$\bar{x}$是f在$[a,b]$上的极小点，并且任意的$x_1,x_2 \in [a,b]$且$x_1<x_2$，有当$x_2\le \bar{x}$时，$f(x_1)>f(x_2)$。当$\bar{x}<x_1$时，$f(x_2)>f(x_1)$则称**f是在闭区间$[a,b]$上的单峰函数**。

![](https://files.mdnice.com/user/25190/c429452e-c409-4622-ad6a-45dd0680d95c.png)

* 性质

定理9.2.1 设f是区间$[a,b]$的单峰函数，$x_1,x_2 \in [a,b]$且$x_1<x_2$。如果$f(x_1)>f(x_2)$，则对每一个$x\in [a,x_1]$，有$f(x)>f(x_2)$；如果$f(x_1)\le f(x_2)$，则对每一个$x\in[x_2,b]$有$f(x)\ge f(x_1)$。

图解上述定理：

![](https://files.mdnice.com/user/25190/37c16859-8997-4555-b34e-3aa92fbb213d.png)

总结：只需要两个试探点，就可将含极小点的区间缩短。

#### 进退法找单峰区间

基本思想：从一点出发，按一定的步长，试图确定出函数呈现“高-低-高”的三点。一个方向不成功，就退回来，再沿相反方向寻找。

进退法的计算步骤：

![](https://files.mdnice.com/user/25190/0a9a82e1-28f5-4b14-8eec-4435499a7664.png)

实际使用中，要注意选择步长$h_0$。如果$h_0$取得太大，则难以确定单峰区间，太小则迭代进展较慢。为了获得合适的$h_0$，有时需要做多次试探才能成功。

#### 黄金分割法
设$f(x)$在$[a_1,b_1]$上单峰，极小点$\bar{x}\in [a_1,b_1]$，又设进行第$k$次迭代时，有$\bar{x}\in [a_k,b_k]$。为缩短包含极小点$\bar{x}$的区间，取两个试探点$\lambda_k,\mu_k\in [a_k,b_k]$，并规定$\lambda_k<\mu_k$计算函数值$f(\lambda_k)$和$f(\mu_k)$。

分两种情形：
1. 若$f(\lambda_k)>f(\mu_k)$，根据定理9.2.1，有$\bar{x}\in [\lambda_k,b_k]$，因此令$a_{k+1}=\lambda_k,b_{k+1}=b_k$
2.  若$f(\lambda_k)\le f(\mu_k)$，根据定理9.2.1，有$\bar{x}\in [a_k,\mu_k]$，因此令$a_{k+1}=a_k,b_{k+1}=\mu_k$

现在确定$\lambda_k$和$\mu_k$，使它们满足两个条件：
1. $\lambda_k$和$\mu_k$在$[a_k,b_k]$中的位置是对称的，即到子空间$[a_k,b_k]$的端点是等距的；
2. 每次迭代区间长度缩短比率相同。

这两个条件即为
$$
b_k-\lambda_k=\mu_k-a_k \tag{9.2.4}
$$
$$
b_{k+1}-a_{k+1}=\tau(b_k-a_k) \tag{9.2.5}
$$

由（9.2.4）式和（9.2.5）式得出计算公式
$$
\lambda_k = a_k+(1-\tau)(b_k-a_k)\tag{9.2.6}
$$
$$
\mu_k = a_k+\tau(b_k-a_k)\tag{9.2.7}
$$

这样通过一个参数$\tau$就可以求得两个参数$\lambda_k,\mu_k$，从而节省了计算量。

在第k次迭代中，会出现上面分析的两种情形
1. 当$f(\lambda_k)\le \mu_k$时

![](https://files.mdnice.com/user/25190/888021fe-3cad-41f2-bbb0-b1c9a3bef7ce.png)

2. 当$f(\lambda_k)> \mu_k$时

![](https://files.mdnice.com/user/25190/70a8104d-c2b8-43a6-bbc8-11ed347c2e2e.png)

分析两种情形得到的$\tau$的值均为0.618，代入（9.2.6），（9.2.7）得到
$$
\lambda_k = a_k+0.382(b_k-a_k)\tag{9.2.10}
$$
$$
\mu_k = a_k+0.618(b_k-a_k)\tag{9.2.11}
$$

综上所述，运用0.618法，初始搜索区间记作$[a_1,b_1]$，以后每次迭代只需按照公式（9.2.10）或（9.2.11）式新计算一点，详细计算步骤如下：

![](https://files.mdnice.com/user/25190/0203636b-0286-4b5d-b343-c20af4df8530.png)

举例：

![](https://files.mdnice.com/user/25190/68ff1364-f691-425d-9d85-21c9c77137d6.png)

在matlab中创建文件Glodenmethod.m用来实现黄金分割法，参数为初始区间，输出迭代次数，最小值对应的$x^*$，最小值。为了更精确的求出最小值，在这里精度设置为``L=1e-4; ``。

```matlab
function [xmin,fmin]=Goldenmethod(a,b)

global counterf
counterf=0;

% set parameters
L=1e-4;     %精度
alpha=(sqrt(5)-1)/2;

% the first loop
ak=a;
bk=b;
lambdak=ak+(1-alpha)*(bk-ak);
muk=ak+alpha*(bk-ak);
flambdak=obj1(lambdak);
fmuk=obj1(muk);

 while 1
    % iteration    
    if flambdak<=fmuk
        bk=muk;
        % keep lambdak as muk, recompute lambdak
        muk=lambdak;
        fmuk=flambdak;        
        lambdak=ak+(1-alpha)*(bk-ak);
        flambdak=obj1(lambdak);        
    else
        ak=lambdak;
        % keep muk as lambdak, recompute muk
        lambdak=muk;
        flambdak=fmuk;
        muk=ak+alpha*(bk-ak);
        fmuk=obj1(muk);
    end
     
     % check stop criterion
    if (bk-ak)<L
        xmin=(ak+bk)/2;
        fmin=obj1(xmin);
        break;
    end
 end

    fprintf("迭代次数：%d\n",counterf);
    fprintf("x星：%.2f\n",xmin);
    fprintf("最小值：%.2f\n",fmin);
end
```

创建obj1.m文件实现目标函数，全局变量couterf用来计算迭代次数。

```matlab
function y=obj1(x)

global counterf
counterf=counterf+1;

y=2*x^2-x-1;
```

最后在命令行输入``Goldenmethod(-1,1)``，得到结果
```
迭代次数：24
x星：0.25
最小值：-1.12
```

根据题目给的目标函数，可以算出$x^*=0.25$，验证了算法的正确性。

#### 黄金分割法的收敛率
1. 当$f(\lambda_k)\le \mu_k$时
$$
\begin{aligned}
b_{k+1}-a_{k+1}&=\mu_k-a_k\\&=a_k+\tau(b_k-a_k)-a_k\\&=\tau(b_k-a_k)\\
\frac{b_{k+1}-a_{k+1}}{b_k-a_k}&=\tau=0.618
\end{aligned}\\
$$
2. 当$f(\lambda_k)> \mu_k$时
$$
\begin{aligned}
b_{k+1}-a_{k+1}&=b_k-\lambda_k\\
&=b_k-a_k-(1-\tau)(b_k-a_k)\\
&=\tau(b_k-a_k)\\
\frac{b_{k+1}-a_{k+1}}{b_k-a_k}&=\tau=0.618
\end{aligned}
$$

从上面的推算可以看出
$$
\begin{aligned}
b_k-a_k&=\tau(b_{k-1}-a_{k-1})\\
&=\tau^2(b_{k-2}-a_{k-2})\\
&=\dots\\
&=\tau^k(b_{0}-a_{0})\\
&<\varepsilon\\
&\Rightarrow k>log_\tau\frac{\varepsilon}{b_0-a_0}
\end{aligned}
$$
即需要$log_\tau\frac{\varepsilon}{b_0-a_0}$次迭代。

### 9.2.2 Fibonacci法
这种方法与0.618法类似，也是用于单峰函数，在计算过程中，也是第一次迭代需要计算两个试探点，以后每次迭代只需新算一点，另一点取自上次迭代。Fibonacci法与0.618法的主要区别之一在于区间长度缩短比率不是常数，而是由所谓的Fibonacci数确定。


Fibonacci数列的定义：

![](https://files.mdnice.com/user/25190/1aab02c4-8dcd-4aab-885a-fcc074e2522e.png)

#### Fibonacci法在迭代中计算试探点的公式

$$
\lambda_k=a_k+\frac{F_{n-k-1}}{F_{n-k+1}}(b_k-a_k),k=1,\dots,n-1\tag{9.2.12}
$$
$$
\mu_k=a_k+\frac{F_{n-k}}{F_{n-k+1}}(b_k-a_k),k=1,\dots,n-1\tag{9.2.13}
$$

n是需要迭代的次数，事先知道次数n，这是Fibonacci法的一个特点。

![](https://files.mdnice.com/user/25190/d75e4ee6-1488-4459-aca6-738d67e68bb7.png)

#### Fibonacci法的收敛率
![](https://files.mdnice.com/user/25190/3cbb52cb-f11e-41ef-95e1-88a10a39b811.png)


![](https://files.mdnice.com/user/25190/e1f3f741-c46a-4702-9c0a-89e1f5e515dc.png)



> 为什么$\lambda_{n-1}=\mu_{n-1}$？

___
把$k=n-1$代入（9.2.12）和（9.2.13）中得到
$$
\lambda_{n-1}=a_{n-1}+\frac{F_{0}}{F_{2}}(b_{n-1}-a_{n-1})
$$
$$
\mu_{n-1}=a_{n-1}+\frac{F_{1}}{F_{2}}(b_{n-1}-a_{n-1})
$$
又因为Fibonacci数列的$F_0=F_1=1,F_2=2$，所以有$\lambda_{n-1}=\mu_{n-1}=\frac{1}{2}(b_{n-1}-a_{n-1})$
___

![](https://files.mdnice.com/user/25190/958768f9-a4f4-4ed8-a8e2-3fbee922433d.png)

#### Fibonacci法的计算步骤
![](https://files.mdnice.com/user/25190/8e0cab37-17cf-4de7-9b97-2d87d6e970c5.png)

举例：题目和黄金分割法的举例一致。
创建Fibonaccimethod.m文件实现Fibonacci法

```matlab
function [xmin,fmin]=Fibonaccimethod(a,b)

global counterf
counterf=0;

% set parameters
L=1e-4;
temp1=(b-a)/L;

% input Fibonacci sequence
k=3;
while 1
    Fibo=P2_fibonacci(k+1);
    if Fibo(k)>=temp1;
        break;
    end
    k=k+1;
end
n=k+1;%迭代次数

ak=a;
bk=b;
 for k=1:n-2
    % check stop criterion
%     lengths=(bk-ak)/2;
%     if lengths<L
%         xmin=meanp;
%         fmin=P2_phi(xmin);
%         break;
%     end
    
    % iteration    
    lengths=bk-ak;
    lambdak=ak+(Fibo(n-k-1)/Fibo(n-k+1))*lengths;
    muk=ak+(Fibo(n-k)/Fibo(n-k+1))*lengths;
    flambdak=obj1(lambdak);
    fmuk=obj1(muk);
    if flambdak<fmuk
        bk=muk;
    else
        ak=lambdak;
    end
 end

xmin=(ak+bk)/2
fmin=obj1(xmin)
counterf

```

创建obj1.m写目标函数
```matlab
function y=obj1(x)

global counterf
counterf=counterf+1;

y=2*x^2-x-1;
```

创建P2_fibonacci.m用来实现Fibonacci数列
```matlab
function Fibo=P2_fibonacci(n)

Fibo=zeros(n,1);

Fibo(1)=1;
Fibo(2)=1;

for i=3:n
    Fibo(i)=Fibo(i-1)+Fibo(i-2);
end
```

在命令行输入 Fibonaccimethod(-1,1)得到以下结果。

```
xmin =
    0.2500
fmin =
   -1.1250
counterf =
    45
ans =
    0.2500
```

从上面的结果可以看出使用Fibonacci法也得到了最小值。

## 黄金分割法与Fibonacci法的关系
0.618法可以作为Fibonacci法的极限形式。

![](https://files.mdnice.com/user/25190/9d1058aa-cb59-4999-8568-802f4f7b7fce.png)

这个极限值正是黄金分割法中的参数$\tau$。


Fibonacci法的精度要高于0.618法，可以通过最终区间长度来比较。0.618法得到的最终区间大约比使用Fibonacci法长17%。可以证明Fibonacci法是分割法求一维极小化问题的最优策略，而0.618法是近似最优的。

Fibonacci法的缺点是要事先知道计算函数值的次数。比较起来0.618法更简单，它不需要事先知道计算函数值的次数，而且收敛速率与Fibonacci法比较接近，当迭代次数$n\ge7$时，$F_{n-1}/F_n\approx 0.618$，因此在解决实际问题时，一般采用0.618法。

## 9.3 函数逼近法
### 9.3.1 牛顿法
#### 基本思想
牛顿法的基本思想是在极小点附近用二阶Taylor多项式近似目标函数$f(x)$，进而求出极小点的估计值。
1. 解方程中的牛顿方法

![解方程中的牛顿方法](https://files.mdnice.com/user/25190/4905cc7c-26bb-47c4-a307-11366b720627.png)

通过计算$f(x)$在$x_k$处的切线的零点找到下一个迭代点。

2. 优化中的牛顿方法

![优化中的牛顿方法](https://files.mdnice.com/user/25190/71f8c24a-5f43-49a4-94b6-e95390b95ec0.png)

通过计算$f(x)$在$x_k$处的二阶泰勒展开计算极小点找到下一个迭代点。

> 定理9.3.1 设$f(x)$存在连续三阶导数，$\bar{x}$满足
> $$f'(x)=0,f''(\bar{x})\neq 0$$
> 初点$x_1$充分接近$\bar{x}$，则牛顿法产生的序列${x_k}$至少以二级收敛速率收敛于$\bar{x}$。

#### 计算步骤

![](https://files.mdnice.com/user/25190/e64ff99b-1a41-4818-992a-569ac749af74.png)

在运用牛顿法时，初点选择十分重要，如果初始点靠近极小点，则可能很快收敛；如果初始点远离极小点，迭代产生的点列可能不收敛于极小点，如下图所示。

![](https://files.mdnice.com/user/25190/d882d96a-338b-4f81-9077-160a2065f3f5.png)

可见牛顿法是局部的算法。

![](https://files.mdnice.com/user/25190/3d59c3a3-7a30-4d69-9b84-63d8b146faef.png)

如上例，当初始点的绝对值大于等于1时，反而不能找到极小值点$x^*=0$。

### 9.3.2 割线法
#### 基本思想
基本思想：用割线逼近目标函数的导函数的曲线$$y=f'(x)$$，把割线的零点作为目标函数的驻点的估计。

![](https://files.mdnice.com/user/25190/7ca72d69-883f-49fd-87e9-f21536d4ff9d.png)

> 定理9.3.2 设$f(x)$存在连续三阶导数，$\bar{x}$满足$f'(\bar{x})=0,f''(\bar{x})\neq0$，若$x_1、x_2$充分接近$\bar{x}$，则割线法产生的序列${x_k}$收敛于$\bar{x}$，则收敛级为1.618。

#### 计算步骤

![](https://files.mdnice.com/user/25190/4a3616ea-5939-47b9-9b49-9e6fe1a2b178.png)

### 9.3.3 抛物线法
#### 基本思想
在极小点附近，用二次三项式$\varphi(x)$逼近目标函数$f(x)$。
令$\varphi(x)$与$f(x)$在三点$x_1,x_2,x_3$处有相同的函数值，并假设
$$
f(x_1)>f(x_2),f(x_2)<f(x_3)
$$
令$\varphi(x)=a+bx+cx^2$，又令
$$
\begin{cases}
\varphi(x_1)=a+bx_1+cx_1^2=f(x_1)\\
\varphi(x_2)=a+bx_2+cx_2^2=f(x_2)\\
\varphi(x_3)=a+bx_3+cx_3^2=f(x_3)\\
\end{cases}
$$
解上述方程得a,b,c。

![](https://files.mdnice.com/user/25190/2c82a5ad-86a0-4ada-b6b7-d9a7ce1029a4.png)

#### 计算步骤

![](https://files.mdnice.com/user/25190/14b1e4ae-5e9f-4c90-aea3-fadf868e18d1.png)

### 9.3.4 二点三次插值法

#### 基本思想

首先取两个初点$x_1,x_2\quad (x_1<x_2)$，使得$f'(x_1)<0$及$f'(x_2)>0$。这样在区间$(x_1,x_2)$内存在极小点。然后利用这两点的函数值和导数构成一个三次多项式$\varphi(x)$，使它与$f(x)$在$x_1$及$x_2$有相同的函数值及相同的导数，用这样的$\varphi(x)$逼近目标函数$f(x)$，进而用$\varphi(x)$的极小点估计$f(x)$的极小点。

设
$$
\begin{aligned}
&\varphi(x)=a(x-x_1)^3+b(x-x_1)^2+c(x-x_1)+d\\
&\varphi(x_1)=f(x_1)\\
&\varphi'(x_1)=f'(x_1)\\
&\varphi(x_2)=f(x_2)\\
&\varphi'(x_2)=f'(x_2)\\
\end{aligned}
$$

解出上述方程组中的$a,b,c,d$ 便可以确定$\varphi(x)$，求出$\varphi(x)$的极小点$\bar{x}$，迭代直到$|x_2-x_1|<\delta$ ，（或直到$|f(\bar{x})|$ 充分小）取此时的 $\bar{x}$ 作为$f(x)$的极小点。

记作
$$
\begin{aligned}
&s=\frac{3[f(x_2)-f(x_1)]}{x_2-x_1}\\
&z=s-f'(x_1)-f'(x_2)\\
&w^2=z^2-f'(x_1)f'(x_2)
\end{aligned}
$$

求出
$$
\bar{x} = x_1+(x_2-x_1)(1-\frac{f'(x_2)+w+z}{f'(x_2)-f'(x_1)+2w})
$$

二点三次插值法的收敛率为2，一般认为这种方法优于抛物线法。

#### 计算步骤
![](https://files.mdnice.com/user/25190/7b54f556-7a09-4d3d-aa70-c30c79c50695.png)

图解：

![](https://files.mdnice.com/user/25190/147f3ef5-b8ae-49db-a3f5-dcd2632b643f.png)



## 一维搜索的总结
|精确一维搜索|方法|特点|收敛率|
|:--|:---|:---|:--:|
|试探法|黄金分割法|用于单峰函数|0.618|
||Fibonacci法|用于单峰函数；缺点是要事先知道迭代次数|当迭代次数$n\ge7$时，收敛率为0.618|
|函数逼近法|牛顿法|需要计算hessian矩阵的逆|2|
||割线法|以一阶导来近似hessian矩阵|1.618|
||抛物线法|初始点：三个；只需计算函数值，不须计算一阶导、二阶导|1.3|
||二点三次插值法|初始点：二个；以目标函数的二点确定一个三次函数，以三次函数的极小点取代目标函数的极小点|2|


## 9.4 非精确线性搜索

![](https://files.mdnice.com/user/25190/fe9f9ff3-26d2-4d0a-b988-543f46c6ea8d.png)

